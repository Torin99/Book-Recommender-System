{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbf00d2",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Book Recommender System - Reinforcement Learning Recommendation Implementation</div>\n",
    "## <div align=\"center\">CP421 Final Project: Data Mining</div>\n",
    "### <div align=\"center\">Group 4</div>\n",
    "#### <div align=\"center\">Due on 06-Dec-2023 at 11:59 PM</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52edb19",
   "metadata": {},
   "source": [
    "##### Imports: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f51c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451baa83",
   "metadata": {},
   "source": [
    "##### ::: Data Preprocessing ::: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230fbeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Display data  of all columns in booksData\\nprint(\"user data\")\\nprint(50 * \"=\")\\nprint(userData)\\nprint(\"book data\")\\nprint(50 * \"=\")\\nprint(booksData)\\nprint(\"rating data\")\\nprint(50 * \"=\")\\nprint(ratingsData)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The below chunk of code, drops null values from all datasets, turns the year_of_publications col to int64,\n",
    "drops all images and image col from df's, converts all col to string (excluding year_of_pub), drops null values from ratings col \n",
    "'''\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_paths = ['Users.csv', 'Books.csv', 'Ratings.csv']\n",
    "\n",
    "# Load data and drop rows with null values\n",
    "userData = pd.read_csv(\"data/\"+file_paths[0], quoting=csv.QUOTE_MINIMAL, quotechar='\"').dropna()\n",
    "\n",
    "\n",
    "booksData = pd.read_csv(\"data/\"+file_paths[1], quoting=csv.QUOTE_MINIMAL, quotechar='\"', \n",
    "                        converters={'Year-Of-Publication': lambda x: pd.to_numeric(x, errors='coerce')}).dropna()\n",
    "# Drop specified columns\n",
    "columns_to_drop = ['Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n",
    "booksData.drop(columns=columns_to_drop, inplace=True)\n",
    "booksData['Year-Of-Publication'] = booksData['Year-Of-Publication'].astype('Int64')\n",
    "\n",
    "# Select columns to convert to strings (excluding 'Year-Of-Publication')\n",
    "columns_to_convert = [col for col in booksData.columns if col != 'Year-Of-Publication']\n",
    "\n",
    "ratingsData = pd.read_csv(\"data/\"+file_paths[2], quoting=csv.QUOTE_MINIMAL, quotechar='\"').dropna()\n",
    "\n",
    "\n",
    "\"\"\"# Display data  of all columns in booksData\n",
    "print(\"user data\")\n",
    "print(50 * \"=\")\n",
    "print(userData)\n",
    "print(\"book data\")\n",
    "print(50 * \"=\")\n",
    "print(booksData)\n",
    "print(\"rating data\")\n",
    "print(50 * \"=\")\n",
    "print(ratingsData)\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ::: Getting the User and their data for the Agent ::: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78fe0771-7db8-47dc-a12c-948d5b4d473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected user ID: 35953\n",
      "       User-ID                   Location   Age\n",
      "35952    35953  forest grove, oregon, usa  37.0\n",
      "==================================================\n",
      "User's ratings:\n",
      "==================================================\n",
      "        User-ID        ISBN  Book-Rating\n",
      "163290    35953  0064434796            4\n",
      "163291    35953  029270822X            0\n",
      "163292    35953  0312959974            7\n",
      "163293    35953  034542526X            0\n",
      "163294    35953  0345435923            0\n",
      "163295    35953  0375412530            8\n",
      "163296    35953  0380702843            0\n",
      "163297    35953  039913493X            0\n",
      "163298    35953  0440174643            0\n",
      "163299    35953  0440226406            0\n",
      "163300    35953  0449006530            0\n",
      "163301    35953  0451208439            0\n",
      "163302    35953  0451520459            0\n",
      "163303    35953  0671002481            8\n",
      "163304    35953  0671795988            0\n",
      "163305    35953  0671877070            0\n",
      "163306    35953  0679417796            8\n",
      "163307    35953  0684872153            0\n",
      "163308    35953  0758204116            9\n",
      "163309    35953  078688097X            0\n",
      "163310    35953  0849933137            0\n",
      "163311    35953  0939165295            0\n",
      "163312    35953  0962789658            0\n",
      "163313    35953  1573220779            8\n"
     ]
    }
   ],
   "source": [
    "# Randomly user who has made multiple ratings\n",
    "current_user = 35953 \n",
    "\n",
    "# Get all ratings of the randomly selected user\n",
    "user_ratings = ratingsData[ratingsData['User-ID'] == current_user]\n",
    "\n",
    "user_info = userData[userData['User-ID'] == current_user][['User-ID', 'Location', 'Age']]\n",
    "\n",
    "\n",
    "print(f\"Randomly selected user ID: {current_user}\")\n",
    "print(user_info)\n",
    "print(50 * \"=\")\n",
    "print(\"User's ratings:\")\n",
    "print(50 * \"=\")\n",
    "print(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cde1ab1-4dbe-48ab-aa13-a2576e6d6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ISBN  Book-Rating   Read  \\\n",
      "0       0195153448           -1  False   \n",
      "1       0002005018           -1  False   \n",
      "2       0060973129           -1  False   \n",
      "3       0374157065           -1  False   \n",
      "4       0393045218           -1  False   \n",
      "...            ...          ...    ...   \n",
      "271349  0440400988           -1  False   \n",
      "271350  0525447644           -1  False   \n",
      "271351  006008667X           -1  False   \n",
      "271352  0192126040           -1  False   \n",
      "271353  0767409752           -1  False   \n",
      "\n",
      "                                               Book-Title  \\\n",
      "0                                     Classical Mythology   \n",
      "1                                            Clara Callan   \n",
      "2                                    Decision in Normandy   \n",
      "3       Flu: The Story of the Great Influenza Pandemic...   \n",
      "4                                  The Mummies of Urumchi   \n",
      "...                                                   ...   \n",
      "271349                         There's a Bat in Bunk Five   \n",
      "271350                            From One to One Hundred   \n",
      "271351  Lily Dale : The True Story of the Town that Ta...   \n",
      "271352                        Republic (World's Classics)   \n",
      "271353  A Guided Tour of Rene Descartes' Meditations o...   \n",
      "\n",
      "                 Book-Author  Year-Of-Publication  \\\n",
      "0         Mark P. O. Morford                 2002   \n",
      "1       Richard Bruce Wright                 2001   \n",
      "2               Carlo D'Este                 1991   \n",
      "3           Gina Bari Kolata                 1999   \n",
      "4            E. J. W. Barber                 1999   \n",
      "...                      ...                  ...   \n",
      "271349        Paula Danziger                 1988   \n",
      "271350            Teri Sloat                 1991   \n",
      "271351      Christine Wicker                 2004   \n",
      "271352                 Plato                 1996   \n",
      "271353   Christopher  Biffle                 2000   \n",
      "\n",
      "                                               Publisher  \n",
      "0                                Oxford University Press  \n",
      "1                                  HarperFlamingo Canada  \n",
      "2                                        HarperPerennial  \n",
      "3                                   Farrar Straus Giroux  \n",
      "4                             W. W. Norton &amp; Company  \n",
      "...                                                  ...  \n",
      "271349                   Random House Childrens Pub (Mm)  \n",
      "271350                                      Dutton Books  \n",
      "271351                                HarperSanFrancisco  \n",
      "271352                           Oxford University Press  \n",
      "271353  McGraw-Hill Humanities/Social Sciences/Languages  \n",
      "\n",
      "[271354 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# getting the books that have actually been reviewed by only the *specific user (..?)\n",
    "\n",
    "unique_books = pd.DataFrame({'ISBN': booksData['ISBN'].unique()})\n",
    "user_book_ratings = pd.merge(unique_books, user_ratings, on='ISBN', how='left')\n",
    "user_book_ratings.drop(columns='User-ID', inplace=True)\n",
    "user_book_ratings['Read'] = ~user_book_ratings['Book-Rating'].isnull()\n",
    "user_book_info = pd.merge(user_book_ratings, booksData)\n",
    "\n",
    "user_book_info['Book-Rating'].fillna(-1, inplace=True)\n",
    "user_book_info['Book-Rating'] = user_book_info['Book-Rating'].astype(int)\n",
    "\n",
    "#books_with_ratings = user_book_info[~user_book_info['Book-Rating'].isnull()] --- this is redundant ??\n",
    "print(user_book_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ::: Reinforcement Learning Recommender ::: #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2e9487-b695-4fef-bf85-932b73805831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Q-learning agent\n",
    "# navigates an environment, learns from experiences, and improves its decision-making \n",
    "# capabilities over time by updating Q-values based on observed rewards and actions\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space_size, state_space_size, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
    "        # Initialize Q-table with zeros\n",
    "        self.q_table = np.zeros((state_space_size, action_space_size))\n",
    "        self.learning_rate = learning_rate  # Set learning rate\n",
    "        self.discount_factor = discount_factor  # Set discount factor for future rewards\n",
    "        self.epsilon = epsilon  # Set epsilon for exploration vs. exploitation trade-off\n",
    "        self.action_space_size = action_space_size  # Number of possible actions\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Epsilon-greedy policy: exploration vs. exploitation\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.randint(self.action_space_size)  # Explore randomly\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state, :])  # Exploit learned values\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        # Q-learning update equation\n",
    "        current_q = self.q_table[state, action]\n",
    "        max_next_q = np.max(self.q_table[next_state, :])\n",
    "        target_q = reward + self.discount_factor * max_next_q * (1 - done)\n",
    "        self.q_table[state, action] += self.learning_rate * (target_q - current_q)\n",
    "\n",
    "# Initialize Q-learning agent\n",
    "agent = QLearningAgent(action_space_size=len(unique_books), state_space_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a80662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended book: 0195153448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN  Book-Rating\n",
      "0  0195153448            7\n",
      "140\n",
      "0393020371\n",
      "\n",
      "::: Recommended Book :::\n",
      "ISBN: 0393020371\n",
      "Title: Next: The Future Just Happened\n",
      "Author: Michael Lewis\n",
      "Year of Publication: 2001\n",
      "Publisher: W.W. Norton &amp; Company\n",
      "\n",
      "\n",
      "Reward to Agent for recommended book: 140\n"
     ]
    }
   ],
   "source": [
    "# Define a custom environment for book recommendation\n",
    "class BookRecommendationEnv(gym.Env):\n",
    "    def __init__(self, books, ratings, agent):\n",
    "        # Initialize the environment with necessary attributes and spaces\n",
    "        self.books = books\n",
    "        self.ratings = ratings\n",
    "        self.book_attributes = ['Book-Author', 'Publisher', 'Year-Of-Publication']\n",
    "        self.action_space = spaces.Discrete(len(unique_books))  # Define action space\n",
    "        self.observation_space = spaces.Discrete(1 + len(self.book_attributes))  # Define observation space\n",
    "        self.current_book_idx = 0\n",
    "        self.done = False\n",
    "        self.agent = agent  # Reference to the Q-learning agent\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to start a new episode\n",
    "        self.current_book_idx = 0\n",
    "        self.done = False\n",
    "        return np.array([self.current_book_idx])  # Return initial state as an array\n",
    "\n",
    "    def step(self, action):\n",
    "        bookID = env.render()\n",
    "        print(f\"Recommended book: {bookID}\")\n",
    "        # Gather user feedback on the recommended book and update the environment state\n",
    "        user_feedback = input(\"Have you read the recommended book? (Y/N): \")\n",
    "        if user_feedback.lower() == 'y':\n",
    "            user_rating = float(input(\"What rating would you give? (0-10): \"))\n",
    "            self.ratings.loc[ratings['ISBN'] == bookID, 'Book-Rating'] = user_rating #add rating to df to be considered for reward\n",
    "            print(self.ratings[self.ratings['ISBN'] == bookID])\n",
    "        else:\n",
    "            user_rating = -1  # Indicates unread\n",
    "        if self.done:\n",
    "            raise ValueError(\"Episode is done. Please call reset to start a new episode.\")\n",
    "        reward = self.calculate_reward(action)  # Calculate reward based on user interaction\n",
    "        print(reward)\n",
    "        next_book_idx = (self.current_book_idx + reward) % len(self.books)\n",
    "        next_state = np.array([next_book_idx])\n",
    "        self.current_book_idx = next_book_idx\n",
    "        return next_state, reward, self.done, {}\n",
    "\n",
    "    def calculate_reward(self, action):\n",
    "        # Calculate the reward based on user ratings for the recommended book\n",
    "        book_id = self.books[action]  # Get book ISBN for the action\n",
    "        user_ratings_for_book = self.ratings[self.ratings['ISBN'] == book_id]['Book-Rating']\n",
    "        \n",
    "        if user_ratings_for_book.empty:\n",
    "            return 0  # If no user ratings found for the book, set default reward\n",
    "        \n",
    "        user_rating = user_ratings_for_book.values[0]\n",
    "        \n",
    "        # Consider user's read status and rating weight in reward calculation\n",
    "        read_status = 1 if user_rating != -1 else 0  # Assume -1 indicates unread\n",
    "        rating_weight = user_rating if user_rating != -1 else 0  # Consider rating as weight if read\n",
    "        \n",
    "        # Perform reward calculation considering factors\n",
    "        reward = (rating_weight * read_status) / 5  # Normalize reward between 0 and 1\n",
    "\n",
    "        return int(reward * 100)  # Scale reward for agent learning\n",
    "\n",
    "    def render(self):\n",
    "        # return the recommended book\n",
    "        return(self.books[self.current_book_idx])\n",
    "\n",
    "\n",
    "# Extract books list and ratings dictionary from the generated data\n",
    "books_list = booksData['ISBN'].tolist()\n",
    "ratings = user_book_info[['ISBN', 'Book-Rating']]\n",
    "\n",
    "# Create the environment\n",
    "env = BookRecommendationEnv(books_list, ratings, agent)\n",
    "\n",
    "# Start a new episode\n",
    "state = env.reset()\n",
    "\n",
    "# Choose an action (recommendation) for the current state using the agent's logic\n",
    "action = agent.choose_action(state)\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "\n",
    "# Render the recommendation\n",
    "print(env.render())\n",
    "recommended_book_isbn = env.render()\n",
    "recommended_book_title = booksData[booksData[\"ISBN\"] == recommended_book_isbn][\"Book-Title\"].values[0]\n",
    "recommended_book_author = booksData[booksData[\"ISBN\"] == recommended_book_isbn][\"Book-Author\"].values[0]\n",
    "recommended_book_year_of_pub = booksData[booksData[\"ISBN\"] == recommended_book_isbn][\"Year-Of-Publication\"].values[0]\n",
    "recommended_book_publisher = booksData[booksData[\"ISBN\"] == recommended_book_isbn][\"Publisher\"].values[0]\n",
    "\n",
    "print()\n",
    "print(f\"::: Recommended Book :::\\nISBN: {recommended_book_isbn}\\nTitle: {recommended_book_title}\\nAuthor: {recommended_book_author}\\nYear of Publication: {recommended_book_year_of_pub}\\nPublisher: {recommended_book_publisher}\\n\")\n",
    "print(f\"\\nReward to Agent for recommended book: {reward}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
